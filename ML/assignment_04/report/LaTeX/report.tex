\documentclass[twoside, a4paper, fleqn, reqno]{article}
\usepackage[
	assignmentNumber=4, 
	authorZero={Stijn Kammer},
	studentNumberZero={4986296},	
	authorOne={Ramon Kits},
	studentNumberOne={5440769},
	groupNumber={31}
]{reportStyle}

\begin{document}

\maketitle

\section{introduction}

\section{Methods}

Vector Quantization makes use of prototype vectors to represent the data and is often used for identification and grouping of clusters in similar data.
To use Vector Quantization, we first need to define a set of prototype vectors $\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_k$.
The prototype vectors are chosen by selecting $k$ data points from the data set.
After which present a single example $\mathbf{x}$, we can find the closest prototype vector $\mathbf{v}_i$ by minimizing the distance between $\mathbf{x}$ and $\mathbf{v}_i$.
The distance between $\mathbf{x}$ and $\mathbf{v}_i$ is defined as the Euclidean distance between the two vectors.
When the closest prototype vector $\mathbf{v}_i$ is found, we move the prototype vector $\mathbf{v}_i$ towards $\mathbf{x}$ by a fraction $\eta$ of the distance between $\mathbf{x}$ and $\mathbf{v}_i$.
Repeat this process for all the examples in the training set and the prototype vectors will converge to a set of vectors that represent the data well.
The prototype vectors are then used to classify new examples. \\

Quantization error is a number that is calculated when using the prototype vectors to classify new examples.
To be able to estimate a good value for $k$, we can use the quantization error to find the optimal value for $k$, the error should be as low as possible.
The quantization error is defined as the sum of distances between the prototype vectors and the examples in the training set.
The quantization error is minimized by moving the prototype vectors towards the examples in the training set.
The quantization error is also minimized by choosing a good set of prototype vectors.
The prototype vectors should be chosen in a way that they are spread out over the data set.
This is done by choosing the prototype vectors to be the $k$ data points that are furthest apart from each other.
The prototype vectors should also be chosen in a way that they are representative of the data set.
This is done by choosing the prototype vectors to be the $k$ data points that are closest to the mean of the data set.

\section{Learning curves}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.1_LR2.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.1$ and $K = 2$}
	\label{fig:error_e20_K0.1_LR2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.01_LR2.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.01$ and $K = 2$}
	\label{fig:error_e20_K0.01_LR2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.1_LR4.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.1$ and $K = 4$}
	\label{fig:error_e20_K0.1_LR4}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.01_LR4.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.01$ and $K = 4$}
	\label{fig:error_e20_K0.01_LR4}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.05_LR2.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.05$ and $K = 2$}
	\label{fig:error_e20_K0.05_LR2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/error_e20_K0.05_LR4.png}
	\caption{Error for $t_{max}=20$, $\eta = 0.05$ and $K = 4$}
	\label{fig:error_e20_K0.05_LR4}
\end{figure}

\section{Trajectories of prototypes}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/vq-learning_e20_K0.1_LR2.png}
	\caption{Learning curve for Vector Quantization with $t_{max}=20$, $\eta=0.1$ and $K=2$}
	\label{fig:vq-learning_e20_K0.1_LR2}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/vq-learning_e20_K0.1_LR4.png}
	\caption{Learning curve for Vector Quantization with $t_{max}=20$, $\eta=0.1$ and $K=4$}
	\label{fig:vq-learning_e20_K0.1_LR4}
\end{figure}

\section{"Stupid" trajectories of prototypes}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../../code/output/vq-learning_e10_K0.1_LR4_stupid.png}
	\caption{Learning curve for Vector Quantization with $t_{max}=10$, $\eta=0.1$ and $K=4$}
	\label{fig:vq-learning_e20_K0.1_LR4_stupid}
\end{figure}

\section{Discussion}

\section{Bonus}

\end{document}